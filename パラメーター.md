## finetrainers/args.py のパラメーター

| パラメーター | 説明 | 型 | デフォルト値 |
|---|---|---|---|
| **model_name** | 学習するモデルの名前。 | str |  |
| **pretrained_model_name_or_path** |  HuggingFace Hub の事前学習済みモデルのパスまたは識別子。 | str | None |
| **revision** | HuggingFace Hub の事前学習済みモデルの識別子のリビジョン。 | Optional[str] | None |
| **variant** | HuggingFace Hub の事前学習済みモデルのモデルファイルのバリアント (例: 'fp16')。 | Optional[str] | None |
| **cache_dir** | ダウンロードしたモデルとデータセットが保存されるディレクトリ。 | Optional[str] | None |
| **text_encoder_dtype** | テキストエンコーダーのデータ型。 | torch.dtype | torch.bfloat16 |
| **text_encoder_2_dtype** | テキストエンコーダー 2 のデータ型。 | torch.dtype | torch.bfloat16 |
| **text_encoder_3_dtype** | テキストエンコーダー 3 のデータ型。 | torch.dtype | torch.bfloat16 |
| **transformer_dtype** | Transformer モデルのデータ型。 | torch.dtype | torch.bfloat16 |
| **vae_dtype** | VAE モデルのデータ型。 | torch.dtype | torch.bfloat16 |
| **data_root** | 学習データを含むフォルダー。 | str | None |
| **dataset_file** | プロンプト/動画パスをこの形式でロードする場合の CSV ファイルへのパス。 | Optional[str] | None |
| **video_column** | 動画を含むデータセットの列。または、`--data_root` フォルダー内の、改行で区切られた動画データへのパスを含むファイルの名前。 | str | None |
| **caption_column** | 各動画のインスタンスプロンプトを含むデータセットの列。または、`--data_root` フォルダー内の、改行で区切られたインスタンスプロンプトを含むファイルの名前。 | str | None |
| **id_token** | 指定された場合、各プロンプトの先頭に追加される識別子トークン。 | Optional[str] | None |
| **image_resolution_buckets** | 画像の解像度バケット。 | List[Tuple[int, int]] | None |
| **video_resolution_buckets** | 動画の解像度バケット。 | List[Tuple[int, int, int]] | None |
| **video_reshape_mode** | すべての入力動画がこのモードにリシェイプされます。['center', 'random', 'none'] から選択。 | Optional[str] | None |
| **caption_dropout_p** | キャプショントークンのドロップアウトの確率。 | float | 0.00 |
| **caption_dropout_technique** | キャプションのドロップアウトに使用する手法。 | str | "empty" |
| **precompute_conditions** | モデルの条件を事前計算するかどうか。 | bool | False |
| **dataloader_num_workers** | データローディングに使用するサブプロセスの数。0 は、データがメインプロセスでロードされることを意味します。 | int | 0 |
| **pin_memory** | Pytorch データローダーで固定メモリ設定を使用するかどうか。 | bool | False |
| **flow_resolution_shifting** | タイムステップスケジュールの解像度依存シフト。 | bool | False |
| **flow_weighting_scheme** |  均一なサンプリングと均一な損失のために、デフォルトでは "none" の重み付けスキームを使用します。 | str | "none" |
| **flow_logit_mean** | `'logit_normal'` の重み付けスキームを使用する場合に使用する平均。 | float | 0.0 |
| **flow_logit_std** | `'logit_normal'` の重み付けスキームを使用する場合に使用する標準偏差。 | float | 1.0 |
| **flow_mode_scale** | モード重み付けスキームのスケール。`weighting_scheme` として `'mode'` を使用する場合にのみ有効です。 | float | 1.29 |
| **training_type** | 実行するトレーニングのタイプ。['lora'] から選択。 | str | None |
| **seed** | 再現可能なトレーニングのためのシード。 | int | 42 |
| **mixed_precision** | 混合精度を使用するかどうか。デフォルトは、現在のシステムの accelerate config の値、または `accelerate.launch` コマンドで渡されたフラグです。accelerate config をオーバーライドするには、この引数を使用します。 | str | None |
| **batch_size** | トレーニングデータローダーのバッチサイズ (デバイスごと)。 | int | 1 |
| **train_epochs** | トレーニングエポック数。 | int | 1 |
| **train_steps** | 実行するトレーニングステップの総数。指定した場合、`--num_train_epochs` をオーバーライドします。 | Optional[int] | None |
| **rank** | LoRA 行列のランク。 | int | 128 |
| **lora_alpha** | LoRA 行列のスケーリングファクター (lora_alpha / rank) を計算するための lora_alpha。 | float | 64 |
| **target_modules** | LoRA のターゲットモジュール。 | List[str] | ["to_k", "to_q", "to_v", "to_out.0"] |
| **gradient_accumulation_steps** | backward/update パスを実行する前に累積する更新ステップ数。 | int | 1 |
| **gradient_checkpointing** | メモリを節約するために勾配チェックポイントを使用するかどうか (ただし、backward パスが遅くなります)。 | bool | False |
| **checkpointing_steps** | トレーニング状態のチェックポイントを X 更新ごとに保存します。これらのチェックポイントは、最後のチェックポイントよりも優れている場合に最終チェックポイントとして使用できるほか、`--resume_from_checkpoint` を使用したトレーニングの再開にも適しています。 | int | 500 |
| **checkpointing_limit** | 保存するチェックポイントの最大数。 | Optional[int] | None |
| **resume_from_checkpoint** | トレーニングを以前のチェックポイントから再開するかどうか。`--checkpointing_steps` で保存されたパスを使用するか、最後に利用可能なチェックポイントを自動的に選択するには `"latest"` を使用します。 | Optional[str] | None |
| **enable_slicing** | メモリを節約するために VAE スライシングを使用するかどうか。 | bool | False |
| **enable_tiling** | メモリを節約するために VAE タイリングを使用するかどうか。 | bool | False |
| **optimizer** | 使用するオプティマイザーのタイプ。 | str | "adamw" |
| **use_8bit_bnb** | `bitsandbytes` を使用して `--optimizer` の 8 ビットバリアントを使用するかどうか。 | bool | False |
| **lr** | 使用する初期学習率 (ウォームアップ期間後)。 | float | 1e-4 |
| **scale_lr** | 学習率を GPU の数、勾配累積ステップ数、およびバッチサイズでスケーリングするかどうか。 | bool | False |
| **lr_scheduler** | 使用するスケジューラーのタイプ。 | str | "cosine_with_restarts" |
| **lr_warmup_steps** | lr スケジューラーのウォームアップのステップ数。 | int | 0 |
| **lr_num_cycles** | cosine_with_restarts スケジューラーでの lr のハードリセットの回数。 | int | 1 |
| **lr_power** | polynomial スケジューラーのパワーファクター。 | float | 1.0 |
| **beta1** | Adam および Prodigy オプティマイザーの beta1 パラメーター。 | float | 0.9 |
| **beta2** | Adam および Prodigy オプティマイザーの beta2 パラメーター。 | float | 0.95 |
| **beta3** | Prodigy オプティマイザーのステップサイズを計算するための係数 (移動平均を使用)。None に設定すると、beta2 の平方根の値が使用されます。 | Optional[float] | 0.999 |
| **weight_decay** | オプティマイザーに使用する weight decay。 | float | 0.0001 |
| **epsilon** | Adam オプティマイザーおよび Prodigy オプティマイザーのイプシロン値。 | float | 1e-8 |
| **max_grad_norm** | 最大勾配ノルム。 | float | 1.0 |
| **validation_prompts** | モデルが学習していることを検証するために検証中に使用される 1 つ以上のプロンプト。複数の検証プロンプトは、'--validation_prompt_seperator' 文字列で区切る必要があります。 | Optional[List[str]] | None |
| **validation_images** | モデルが学習していることを検証するために検証中に使用される 1 つ以上の画像パス/URL。複数の検証パスは、'--validation_prompt_seperator' 文字列で区切る必要があります。これらは、検証プロンプトの順序に対応する必要があります。 | Optional[List[str]] | None |
| **validation_videos** | モデルが学習していることを検証するために検証中に使用される 1 つ以上の動画パス/URL。複数の検証パスは、'--validation_prompt_seperator' 文字列で区切る必要があります。これらは、検証プロンプトの順序に対応する必要があります。 | Optional[List[str]] | None |
| **num_validation_videos_per_prompt** | `validation_prompt` ごとに検証中に生成する必要がある動画の数。 | int | 1 |
| **validation_every_n_epochs** | X トレーニングエポックごとに検証を実行します。検証は、検証プロンプトを `args.num_validation_videos` 回実行することで構成されます。 | Optional[int] | None |
| **validation_every_n_steps** | X トレーニングステップごとに検証を実行します。検証は、検証プロンプトを `args.num_validation_videos` 回実行することで構成されます。 | Optional[int] | None |
| **enable_model_cpu_offload** | 検証/テストの実行時にメモリを節約するために、モデルごとの CPU オフロードを有効にするかどうか。 | bool | False |
| **tracker_name** | プロジェクトトラッカー名。 | str | "finetrainers" |
| **push_to_hub** | モデルを Hub にプッシュするかどうか。 | bool | False |
| **hub_token** | Model Hub へのプッシュに使用するトークン。 | Optional[str] | None |
| **hub_model_id** | ローカルの `output_dir` と同期させるリポジトリの名前。 | Optional[str] | None |
| **output_dir** | モデルの予測とチェックポイントが書き込まれる出力ディレクトリ。 | str | "finetrainer-training" |
| **logging_dir** | ログが保存されるディレクトリ。 | Optional[str] | "logs" |
| **allow_tf32** | Ampere GPU で TF32 を許可するかどうか。トレーニングを高速化するために使用できます。詳細については、https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices を参照してください。 | bool | False |
| **nccl_timeout** | multi-GPU/multi-node トレーニング設定で allgather または関連操作が失敗するまでの最大タイムアウト時間。 | int | 1800 |
| **report_to** | 結果とログをレポートする統合。サポートされているプラットフォームは、`"tensorboard"` (デフォルト)、`"wandb"`、および `"comet_ml"` です。すべての統合にレポートするには、`"all"` を使用します。 | str | "wandb" |
